{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DataScientistTX/NLP_tabular/blob/main/examples.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "piBrI5ukuZSg"
      },
      "source": [
        "# Chat with Data Notebook (Embedded Tables)\n",
        "\n",
        "In this notebook we walk you through an advanced RAG use case - parsing a complex document with embedded tables - and how to handle that in LlamaIndex.\n",
        "\n",
        "We compare our approach against a \"naive\" RAG stack (using top-k retrieval with a fixed chunk size).\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M4aWI5yfuC22",
        "outputId": "4fb1894c-b30b-46ab-c7ca-4a9463061216"
      },
      "outputs": [],
      "source": [
        "#!pip install llama-index llama-hub pypdf --upgrade\n",
        "#!apt install ghostscript python3-tk\n",
        "#!pip install camelot-py pymupdf frontend ghostscript\n",
        "!wget \"https://www.dropbox.com/scl/fi/waoz9bo9yiemnhnqvu0cc/billionaires_page.pdf?rlkey=4i08msa7zr1lpnuq2y1vs2xgw&dl=1\" -O billionaires_page.pdf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ht4oSN2PvzUJ"
      },
      "outputs": [],
      "source": [
        "# setup OpenAI\n",
        "import openai\n",
        "\n",
        "openai.api_key = \"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k3CGRBjsuLCB"
      },
      "outputs": [],
      "source": [
        "import nest_asyncio\n",
        "\n",
        "nest_asyncio.apply()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VhuXtvSX2mWo"
      },
      "outputs": [],
      "source": [
        "from IPython.display import HTML, display\n",
        "\n",
        "def set_css():\n",
        "  display(HTML('''\n",
        "  <style>\n",
        "    pre {\n",
        "        white-space: pre-wrap;\n",
        "    }\n",
        "  </style>\n",
        "  '''))\n",
        "get_ipython().events.register('pre_run_cell', set_css)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Y0CWFcEv61y"
      },
      "source": [
        "## Complex Document (with Embedded Tables)\n",
        "\n",
        "In this setting we walk through a document that has an embedded table inside of it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "BqJQDrZqzAEp",
        "outputId": "9e9c0ab8-b02c-453f-b772-3fb98d1dd6f4"
      },
      "outputs": [],
      "source": [
        "import camelot\n",
        "from llama_index import Document, SummaryIndex\n",
        "\n",
        "# https://en.wikipedia.org/wiki/The_World%27s_Billionaires\n",
        "from llama_index import VectorStoreIndex, ServiceContext, LLMPredictor\n",
        "from llama_index.query_engine import PandasQueryEngine, RetrieverQueryEngine\n",
        "from llama_index.retrievers import RecursiveRetriever\n",
        "from llama_index.schema import IndexNode\n",
        "from llama_index.llms import OpenAI\n",
        "\n",
        "from llama_hub.file.pymu_pdf.base import PyMuPDFReader\n",
        "from pathlib import Path\n",
        "from typing import List"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ok7qgGuyzRMx"
      },
      "source": [
        "### Parse out Table, build Pandas Query Engine"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 575
        },
        "id": "-FyhtIy43ZWQ",
        "outputId": "5de06145-f95d-4f0a-9459-ce30f9938b30"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "bk7Aj3x1zC0P",
        "outputId": "547b70d0-19e5-4226-c6a6-0377f232e56e"
      },
      "outputs": [],
      "source": [
        "# initialize PDF reader\n",
        "reader = PyMuPDFReader()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "A48MFvCHzELc",
        "outputId": "0da1b6d9-dc24-4367-b53a-ba878978db39"
      },
      "outputs": [],
      "source": [
        "file_path = \"billionaires_page.pdf\"\n",
        "docs = reader.load(file_path=file_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "qUFUJFMjzFaR",
        "outputId": "be94b1e3-508f-4bc2-a170-ba24a3779cc4"
      },
      "outputs": [],
      "source": [
        "# use camelot to parse tables\n",
        "def get_tables(path: str, pages: List[int]):\n",
        "    table_dfs = []\n",
        "    for page in pages:\n",
        "        table_list = camelot.read_pdf(path, pages=str(page))\n",
        "        table_df = table_list[0].df\n",
        "        table_df = (\n",
        "            table_df.rename(columns=table_df.iloc[0])\n",
        "            .drop(table_df.index[0])\n",
        "            .reset_index(drop=True)\n",
        "        )\n",
        "        table_dfs.append(table_df)\n",
        "    return table_dfs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "prSCnWjWzGvN",
        "outputId": "02283c68-8211-4b55-952d-d7c75e7688f7"
      },
      "outputs": [],
      "source": [
        "table_dfs = get_tables(file_path, pages=[3, 25])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "R7_MxDU_zIEx",
        "outputId": "7185950a-8fc1-4a61-e068-5fa7486c2405"
      },
      "outputs": [],
      "source": [
        "# shows list of top billionaires in 2023\n",
        "table_dfs[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 833
        },
        "id": "wnvCdO78zJ3v",
        "outputId": "1778ef06-3e3b-4275-fc84-ba672adb0aba"
      },
      "outputs": [],
      "source": [
        "# shows list of top billionaires\n",
        "table_dfs[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "Q-NdLsc9zLZg",
        "outputId": "c1f39034-4673-4b14-974c-ea48a209a0a5"
      },
      "outputs": [],
      "source": [
        "# define query engines over these tables\n",
        "df_query_engines = [PandasQueryEngine(table_df) for table_df in table_dfs]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "tmksOoRuzMxe",
        "outputId": "e6b9fcfc-14ee-4654-a4dc-3d3bf4200c43"
      },
      "outputs": [],
      "source": [
        "response = df_query_engines[0].query(\n",
        "    \"What's the net worth of the second richest billionaire in 2023?\"\n",
        ")\n",
        "print(str(response))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "iYeIkl0wzN4H",
        "outputId": "7cb30624-3ed4-4da7-8ba9-d98001d5ef3f"
      },
      "outputs": [],
      "source": [
        "response = df_query_engines[1].query(\"How many billionaires were there in 2009?\")\n",
        "print(str(response))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YPhTPOALzTf8"
      },
      "source": [
        "### Build Recursive Retriever\n",
        "\n",
        "We define a top-level vector index that does top-k lookup over a set of Nodes. We define two special nodes (`IndexNode` objects) linking to each of these tables.\n",
        "\n",
        "We define a `RecursiveRetriever` object to recursively retrieve/query nodes. We then put this in our `RetrieverQueryEngine` along with a `ResponseSynthesizer` to synthesize a response.\n",
        "\n",
        "We pass in mappings from id to retriever and id to query engine. We then pass in a root id representing the retriever we query first."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "Q16ooq0vzenz",
        "outputId": "a03d0573-8f32-4476-db72-c9967c165dc9"
      },
      "outputs": [],
      "source": [
        "llm = OpenAI(temperature=0, model=\"gpt-4\")\n",
        "\n",
        "service_context = ServiceContext.from_defaults(\n",
        "    llm=llm,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "HzEleylizfl9",
        "outputId": "2de31aaa-b3b2-4b84-96c9-b66d2117c4dc"
      },
      "outputs": [],
      "source": [
        "doc_nodes = service_context.node_parser.get_nodes_from_documents(docs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "Ix5wBtHTzg8o",
        "outputId": "4b240741-885a-4f60-b029-dd696ed119a2"
      },
      "outputs": [],
      "source": [
        "# define index nodes\n",
        "summaries = [\n",
        "    \"This node provides information about the world's richest billionaires in 2023\",\n",
        "    \"This node provides information on the number of billionaires and their combined net worth from 2000 to 2023.\",\n",
        "]\n",
        "\n",
        "df_nodes = [\n",
        "    IndexNode(text=summary, index_id=f\"pandas{idx}\")\n",
        "    for idx, summary in enumerate(summaries)\n",
        "]\n",
        "\n",
        "df_id_query_engine_mapping = {\n",
        "    f\"pandas{idx}\": df_query_engine\n",
        "    for idx, df_query_engine in enumerate(df_query_engines)\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "I_8SoJwEzh6C",
        "outputId": "3eec8820-88af-4745-92ff-c0e3095f59e0"
      },
      "outputs": [],
      "source": [
        "# construct top-level vector index + query engine\n",
        "vector_index = VectorStoreIndex(doc_nodes + df_nodes)\n",
        "vector_retriever = vector_index.as_retriever(similarity_top_k=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "_IlcUcCQzpdG",
        "outputId": "f476e6a3-b8c7-4201-c3f4-fbdfc48e78fb"
      },
      "outputs": [],
      "source": [
        "from llama_index.retrievers import RecursiveRetriever\n",
        "from llama_index.query_engine import RetrieverQueryEngine\n",
        "from llama_index.response_synthesizers import get_response_synthesizer\n",
        "\n",
        "recursive_retriever = RecursiveRetriever(\n",
        "    \"vector\",\n",
        "    retriever_dict={\"vector\": vector_retriever},\n",
        "    query_engine_dict=df_id_query_engine_mapping,\n",
        "    verbose=True,\n",
        ")\n",
        "\n",
        "response_synthesizer = get_response_synthesizer(\n",
        "    # service_context=service_context,\n",
        "    response_mode=\"compact\"\n",
        ")\n",
        "\n",
        "query_engine = RetrieverQueryEngine.from_args(\n",
        "    recursive_retriever, response_synthesizer=response_synthesizer\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ol-2hQ9hzqp_"
      },
      "source": [
        "### Define Baseline Retriever\n",
        "\n",
        "We also define a baseline retriever that does top-k lookup over the raw document."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "KxMk4zehipBf",
        "outputId": "4cdc5cb3-30b6-4144-abb4-f740cface9e8"
      },
      "outputs": [],
      "source": [
        "# baseline vector index (that doesn't include the extra df nodes).\n",
        "# used to benchmark\n",
        "vector_index0 = VectorStoreIndex(doc_nodes)\n",
        "vector_query_engine0 = vector_index0.as_query_engine()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YRsB_28_isCA"
      },
      "source": [
        "### Compare Results\n",
        "\n",
        "We compare results between the recursive retriever vs. baseline retriever."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "id": "Ymguy0KGztxd",
        "outputId": "9fcb5ae8-ea65-45c3-df73-faecdca71f8e"
      },
      "outputs": [],
      "source": [
        "response = query_engine.query(\n",
        "    \"How many billionaires were there in 2009?\"\n",
        ")\n",
        "print(str(response))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "TIM0KPcYz2t2",
        "outputId": "cf41d562-7ae3-43cc-a7e3-48b4b4ec43b6"
      },
      "outputs": [],
      "source": [
        "response.source_nodes[0].node.get_content()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "Ylgg7AYYzxLd",
        "outputId": "7c682903-18ef-4bc0-f1ac-3f0e2632f108"
      },
      "outputs": [],
      "source": [
        "response = vector_query_engine0.query(\n",
        "    \"How many billionaires were there in 2009?\"\n",
        ")\n",
        "print(str(response))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "MCLtfVdNz5Op",
        "outputId": "6be1aa74-a7b0-42de-8fc5-f7ce82d36600"
      },
      "outputs": [],
      "source": [
        "print(response.source_nodes[1].node.get_content())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 138
        },
        "id": "kQZhiiIJjB_s",
        "outputId": "9f0197c3-8331-434e-ea00-18a402f061cb"
      },
      "outputs": [],
      "source": [
        "response = query_engine.query(\n",
        "    \"What is the average age of top 5 billionaires in 2023? Make sure age is a float.\"\n",
        ")\n",
        "print(str(response))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "gbWsicqqjXYi",
        "outputId": "c017b4fc-baa4-42b9-93ef-f4facbc46822"
      },
      "outputs": [],
      "source": [
        "response = vector_query_engine0.query(\n",
        "    \"What is the average age of top 5 billionaires in 2023? Make sure age is a float.\"\n",
        ")\n",
        "print(str(response))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PVEtBgX4kiaj"
      },
      "source": [
        "Of course, just like the baseline vector query engine, the recursive retriever can answer semantic queries over the article as well."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "cpe2JqBfkf7K",
        "outputId": "64556143-ae02-4699-997b-17807ddb6151"
      },
      "outputs": [],
      "source": [
        "response = query_engine.query(\n",
        "    \"How is wealth accounted for in recipients if the billionaire is deceased?\"\n",
        ")\n",
        "print(str(response))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "id": "IPZJRbJnk_s4",
        "outputId": "e1a917b1-abe1-40f8-b55e-523c5f153b7b"
      },
      "outputs": [],
      "source": [
        "response = vector_query_engine0.query(\n",
        "    \"How is wealth accounted for in recipients if the billionaire is deceased?\"\n",
        ")\n",
        "print(str(response))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i3ZaPyxG_4j2"
      },
      "source": [
        "## Extended Use Case: Parsing Tesla 10Qs\n",
        "\n",
        "Here we deal with an even messier document format - parsing tables within a 10K.\n",
        "\n",
        "We use the Unstructured library to help us extract tables.\n",
        "\n",
        "The tables aren't perfectly formatted, but work well enough."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "oJT0MpiCCqiK",
        "outputId": "1e3985da-df4f-489a-b628-8400be5ed1d4"
      },
      "outputs": [],
      "source": [
        "!pip install unstructured"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-rgNa4raBP91"
      },
      "source": [
        "### Extract Elements"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "_lIcAz6sAEnI",
        "outputId": "c7827bed-2b4c-488d-8057-22427f3a99d4"
      },
      "outputs": [],
      "source": [
        "from pydantic import BaseModel\n",
        "from unstructured.partition.html import partition_html\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "wf5G_ne_AG-Z",
        "outputId": "e2c32758-06f0-4722-ac51-3352509de6a1"
      },
      "outputs": [],
      "source": [
        "!wget \"https://www.dropbox.com/scl/fi/mlaymdy1ni1ovyeykhhuk/tesla_2021_10k.htm?rlkey=qf9k4zn0ejrbm716j0gg7r802&dl=1\" -O tesla_2021_10k.htm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "QhkoN2ayAH7F",
        "outputId": "1ff1f8d8-4a43-46d5-bc1c-6ea5c060f6b3"
      },
      "outputs": [],
      "source": [
        "from llama_index.readers.file.flat_reader import FlatReader\n",
        "from pathlib import Path\n",
        "\n",
        "reader = FlatReader()\n",
        "docs_2021 = reader.load_data(Path(\"tesla_2021_10k.htm\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "omfHCg8IAJ6c",
        "outputId": "ffbc66b5-6396-4634-af7c-d4af3b8d59dd"
      },
      "outputs": [],
      "source": [
        "from llama_index.node_parser import (\n",
        "    UnstructuredElementNodeParser,\n",
        ")\n",
        "\n",
        "node_parser = UnstructuredElementNodeParser()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "id": "B43MNRgSAK4F",
        "outputId": "5c4e4c1e-0580-410c-afa7-2120bc4bb1c0"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pickle\n",
        "\n",
        "if not os.path.exists(\"2021_nodes.pkl\"):\n",
        "    raw_nodes_2021 = node_parser.get_nodes_from_documents(docs_2021)\n",
        "    pickle.dump(raw_nodes_2021, open(\"2021_nodes.pkl\", \"wb\"))\n",
        "else:\n",
        "    raw_nodes_2021 = pickle.load(open(\"2021_nodes.pkl\", \"rb\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LQclEz8TAnsc"
      },
      "outputs": [],
      "source": [
        "base_nodes_2021, node_mappings_2021 = node_parser.get_base_nodes_and_mappings(\n",
        "    raw_nodes_2021\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cAh5Q9MrAo7x"
      },
      "outputs": [],
      "source": [
        "example_index_node = [b for b in base_nodes_2021 if isinstance(b, IndexNode)][\n",
        "    20\n",
        "]\n",
        "\n",
        "# Index Node\n",
        "print(\n",
        "    f\"\\n--------\\n{example_index_node.get_content(metadata_mode='all')}\\n--------\\n\"\n",
        ")\n",
        "# Index Node ID\n",
        "print(f\"\\n--------\\nIndex ID: {example_index_node.index_id}\\n--------\\n\")\n",
        "# Referenceed Table\n",
        "print(\n",
        "    f\"\\n--------\\n{node_mappings_2021[example_index_node.index_id].get_content()}\\n--------\\n\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jiEXTOJJArVZ"
      },
      "source": [
        "### Build Recursive Retriever"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HoqKWlF2Asrk"
      },
      "outputs": [],
      "source": [
        "from llama_index.retrievers import RecursiveRetriever\n",
        "from llama_index.query_engine import RetrieverQueryEngine\n",
        "from llama_index import VectorStoreIndex, ServiceContext\n",
        "from llama_index.llms import OpenAI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5WwTWCedAuib"
      },
      "outputs": [],
      "source": [
        "llm = OpenAI(model=\"gpt-4-1106-preview\")\n",
        "service_context = ServiceContext.from_defaults(llm=llm)\n",
        "\n",
        "# construct top-level vector index + query engine\n",
        "vector_index = VectorStoreIndex(base_nodes_2021, service_context=service_context)\n",
        "vector_retriever = vector_index.as_retriever(similarity_top_k=1)\n",
        "vector_query_engine = vector_index.as_query_engine(similarity_top_k=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_vUeCatwAvZ1"
      },
      "outputs": [],
      "source": [
        "from llama_index.retrievers import RecursiveRetriever\n",
        "\n",
        "recursive_retriever = RecursiveRetriever(\n",
        "    \"vector\",\n",
        "    retriever_dict={\"vector\": vector_retriever},\n",
        "    node_dict=node_mappings_2021,\n",
        "    verbose=True,\n",
        ")\n",
        "query_engine = RetrieverQueryEngine.from_args(recursive_retriever)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qurWIG1JAwjK"
      },
      "source": [
        "### Run Some Queries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eFQF6aXdAxTD"
      },
      "outputs": [],
      "source": [
        "response = query_engine.query(\"What was the revenue in 2020?\")\n",
        "print(str(response))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9L0XyEDmAyY9"
      },
      "outputs": [],
      "source": [
        "# compare against the baseline retriever\n",
        "response = vector_query_engine.query(\"What was the revenue in 2020?\")\n",
        "print(str(response))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "V100",
      "include_colab_link": true,
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
